# -*- coding: utf-8 -*-
"""25-5-24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18OqDjnGn_Nyk5lTr0Pj5shv4fKCzNAXR

#Water Quality and Portability Prediction Using Machine Learning
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("/content/water_quality.csv")

df.head()

df.tail()

df.shape

df.columns

df.info()

df.describe()

df.duplicated().sum()

df.isnull().sum()

df.nunique()

"""#Data Cleaning"""

plt.figure(figsize=(15,6))
sns.histplot(df['ph'], bins = 20, kde = True, palette='hls')
plt.xticks(rotation = 90)
plt.show()

plt.figure(figsize=(15,6))
sns.histplot(df['Sulfate'], bins = 20, kde = True, palette='hls')
plt.xticks(rotation = 90)
plt.show()

plt.figure(figsize=(15,6))
sns.histplot(df['Trihalomethanes'], bins = 20, kde = True, palette='hls')
plt.xticks(rotation = 90)
plt.show()

ph_median = df['ph'].median()
sulfate_median = df['Sulfate'].median()
trihalomethanes_median = df['Trihalomethanes'].median()

df['ph'].fillna(ph_median, inplace=True)
df['Sulfate'].fillna(sulfate_median, inplace=True)
df['Trihalomethanes'].fillna(trihalomethanes_median, inplace=True)

df.isnull().sum()

df.duplicated().sum()

"""#Data Classification"""

object_columns = df.select_dtypes(include=['object']).columns
print("Object type columns:")
print(object_columns)

numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns
print("\nNumerical type columns:")
print(numerical_columns)

def classify_features(df):
    categorical_features = []
    non_categorical_features = []
    discrete_features = []
    continuous_features = []

    for column in df.columns:
        if df[column].dtype == 'object':
            if df[column].nunique() < 10:
                categorical_features.append(column)
            else:
                non_categorical_features.append(column)
        elif df[column].dtype in ['int64', 'float64']:
            if df[column].nunique() < 15:
                discrete_features.append(column)
            else:
                continuous_features.append(column)

    return categorical_features, non_categorical_features, discrete_features, continuous_features

categorical, non_categorical, discrete, continuous = classify_features(df)

print("Categorical Features:", categorical)
print("Non-Categorical Features:", non_categorical)
print("Discrete Features:", discrete)
print("Continuous Features:", continuous)

"""#Data Visualization"""

for i in discrete:
    print(i)
    print(df[i].unique())
    print()

for i in discrete:
    print(df[i].value_counts())
    print()

for i in discrete:
    plt.figure(figsize=(15, 6))
    ax = sns.countplot(x=i, data=df, palette='hls')

    for p in ax.patches:
        height = p.get_height()
        ax.annotate(f'{height}',
                    xy=(p.get_x() + p.get_width() / 2., height),
                    xytext=(0, 10),
                    textcoords='offset points',
                    ha='center', va='center')

    plt.show()

import plotly.express as px

for i in discrete:
    counts = df[i].value_counts()
    fig = px.pie(counts, values=counts.values, names=counts.index, title=f'Distribution of {i}')
    fig.show()

for i in continuous:
    plt.figure(figsize=(15,6))
    sns.histplot(df[i], bins = 20, kde = True, palette='hls')
    plt.xticks(rotation = 90)
    plt.show()

for i in continuous:
    plt.figure(figsize=(15,6))
    sns.distplot(df[i], bins = 20, kde = True)
    plt.xticks(rotation = 90)
    plt.show()

for i in continuous:
    plt.figure(figsize=(15, 6))
    sns.boxplot(x=i, data=df, palette='hls')
    plt.xticks(rotation=90)
    plt.show()

for i in continuous:
    plt.figure(figsize=(15, 6))
    sns.boxenplot(x=i, data=df, palette='hls')
    plt.xticks(rotation=90)
    plt.show()

for i in continuous:
    plt.figure(figsize=(15, 6))
    sns.violinplot(x=i, data=df, palette='hls')
    plt.xticks(rotation=90)
    plt.show()

for i in continuous:
    for j in continuous:
        if i !=j:
            plt.figure(figsize=(15, 6))
            sns.scatterplot(x=i, y=j, data=df, palette='hls')
            plt.title(f'Scatter plot')
            plt.show()

for cat in discrete:
    for cont in continuous:
        plt.figure(figsize=(10, 6))
        ax = sns.barplot(data=df, x=cat, y=cont, ci=None)
        plt.title(f'{cat} vs {cont}')

        for p in ax.patches:
            height = p.get_height()
            ax.annotate(f'{height:.2f}', (p.get_x() + p.get_width() / 2., height),
                        ha='center', va='bottom', fontsize=10, color='black', rotation=0)
        plt.xticks(rotation = 90)
        plt.show()

for cat in discrete:
    for cont in continuous:
        plt.figure(figsize=(10, 6))
        ax = sns.boxplot(data=df, x=cat, y=cont)
        plt.title(f'{cat} vs {cont}')

        plt.xticks(rotation = 90)
        plt.show()

for i in continuous:
    for j in continuous:
        if i !=j:
            plt.figure(figsize=(15, 6))
            sns.scatterplot(x=i, y=j, data=df, palette='hls',hue='Potability')
            plt.title(f'Scatter plot')
            plt.show()

df1 = df[['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity','Organic_carbon', 'Trihalomethanes', 'Turbidity']]

Q1 = df1.quantile(0.25)
Q3 = df1.quantile(0.75)
IQR = Q3 - Q1

Q1

Q3

IQR

x = Q1 - 1.5 * IQR

x

x = Q3 + 1.5 * IQR

x

df2 = df[~((df1 < (Q1 - 1.5 * IQR)) | (df1 > (Q3 + 1.5 * IQR))).any(axis = 1)]

df2

corr = df2.corr()

corr

plt.figure(figsize=(20,10))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.show()

categorical, non_categorical, discrete, continuous = classify_features(df2)

print("Categorical Features:", categorical)
print("Non-Categorical Features:", non_categorical)
print("Discrete Features:", discrete)
print("Continuous Features:", continuous)

for i in discrete:
    counts = df2[i].value_counts()
    fig = px.pie(counts, values=counts.values, names=counts.index, title=f'Distribution of {i}')
    fig.show()

for i in continuous:
    plt.figure(figsize=(15,6))
    sns.histplot(df2[i], bins = 20, kde = True, palette='hls')
    plt.xticks(rotation = 90)
    plt.show()

X = df2.drop('Potability', axis=1)
y = df2['Potability']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify = y,
                                                    random_state=42)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

log_reg = LogisticRegression(random_state=42)
log_reg.fit(X_train_resampled, y_train_resampled)

y_pred = log_reg.predict(X_test)

print("Logistic Regression:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.svm import SVC

smote = SMOTE(random_state=42)
X_train_resampled_new, y_train_resampled_new = smote.fit_resample(X_train_sc, y_train)

svc = SVC(random_state=42)
svc.fit(X_train_resampled_new, y_train_resampled_new)

y_pred = svc.predict(X_test)

print("Support Vector Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier(random_state=42)
dtc.fit(X_train_resampled, y_train_resampled)

y_pred = dtc.predict(X_test)

print("Decision Tree Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

dtc_new = DecisionTreeClassifier(random_state=42)
dtc_new.fit(X_train_resampled_new, y_train_resampled_new)

y_pred = dtc_new.predict(X_test)

print("Decision Tree Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

svc = SVC(random_state=42)
svc.fit(X_train_resampled, y_train_resampled)

y_pred = svc.predict(X_test)

print("Support Vector Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.model_selection import GridSearchCV

param_grid_log_reg = {
    'C': [0.1, 1, 10, 100],
    'solver': ['liblinear', 'sag']
}

log_reg = LogisticRegression(random_state=42)
grid_search_log_reg = GridSearchCV(log_reg, param_grid_log_reg, cv=5, scoring='accuracy')
grid_search_log_reg.fit(X_train_resampled, y_train_resampled)

best_log_reg = grid_search_log_reg.best_estimator_
y_pred_log_reg = best_log_reg.predict(X_test)

print("Best Logistic Regression parameters:", grid_search_log_reg.best_params_)
print("Accuracy:", accuracy_score(y_test, y_pred_log_reg))
print(classification_report(y_test, y_pred_log_reg))

param_grid_dtc = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

dtc = DecisionTreeClassifier(random_state=42)
grid_search_dtc = GridSearchCV(dtc, param_grid_dtc, cv=5, scoring='accuracy')
grid_search_dtc.fit(X_train_resampled, y_train_resampled)

best_dtc = grid_search_dtc.best_estimator_
y_pred_dtc = best_dtc.predict(X_test)

print("Best Decision Tree parameters:", grid_search_dtc.best_params_)
print("Accuracy:", accuracy_score(y_test, y_pred_dtc))
print(classification_report(y_test, y_pred_dtc))

param_grid_svc = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['linear', 'poly','sigmoid']
}

svc = SVC(random_state=42)
grid_search_svc=GridSearchCV(svc, param_grid_svc, cv=5, scoring='accuracy')
grid_search_svc.fit(X_train_resampled, y_train_resampled)

best_svc = grid_search_svc.best_estimator_
y_pred_svc = best_svc.predict(X_test)

print("Best SVC parameters:", grid_search_svc.best_params_)
print("Accuracy:", accuracy_score(y_test, y_pred_svc))
svc.fit(X_train_resampled_new, y_train_resampled_new)

